#
# This file is autogenerated by pip-compile with python 3.10
# To update, run:
#
#    pip-compile --output-file=requirements.txt requirements.in
#
aiohttp==3.7.4.post0
    # via
    #   -r requirements.in
    #   slackclient
async-timeout==3.0.1
    # via aiohttp
attrs==20.3.0
    # via
    #   aiohttp
    #   automat
    #   jsonschema
    #   service-identity
    #   twisted
automat==20.2.0
    # via twisted
awscli==1.19.62
    # via
    #   -r requirements.in
    #   scrapy-dotpersistence
boto==2.49.0
    # via
    #   -r requirements.in
    #   spidermon
boto3==1.17.62
    # via
    #   -r requirements.in
    #   spidermon
botocore==1.20.62
    # via
    #   awscli
    #   boto3
    #   s3transfer
bsddb3==6.2.9
    # via scrapy-deltafetch
cachetools==4.2.2
    # via premailer
certifi==2020.12.5
    # via
    #   requests
    #   sentry-sdk
cffi==1.14.5
    # via cryptography
chardet==4.0.0
    # via
    #   aiohttp
    #   requests
colorama==0.4.3
    # via awscli
constantly==15.1.0
    # via twisted
cryptography==3.4.7
    # via
    #   -r requirements.in
    #   pyopenssl
    #   scrapy
    #   service-identity
cssselect==1.1.0
    # via
    #   parsel
    #   premailer
    #   scrapy
cssutils==2.2.0
    # via premailer
docutils==0.15.2
    # via awscli
filelock==3.6.0
    # via tldextract
hyperlink==21.0.0
    # via twisted
idna==2.10
    # via
    #   hyperlink
    #   jsonschema
    #   requests
    #   tldextract
    #   yarl
incremental==21.3.0
    # via twisted
itemadapter==0.2.0
    # via
    #   itemloaders
    #   scrapy
itemloaders==1.0.4
    # via scrapy
jinja2==2.11.3
    # via
    #   -r requirements.in
    #   spidermon
jmespath==0.10.0
    # via
    #   boto3
    #   botocore
    #   itemloaders
jsonpointer==2.1
    # via jsonschema
jsonschema[format]==3.2.0
    # via spidermon
lxml==4.6.3
    # via
    #   -r requirements.in
    #   parsel
    #   premailer
    #   scrapy
markupsafe==1.1.1
    # via jinja2
monkeylearn==3.5.2
    # via -r requirements.in
multidict==5.1.0
    # via
    #   aiohttp
    #   yarl
parsel==1.6.0
    # via
    #   itemloaders
    #   scrapy
pillow==8.2.0
    # via -r requirements.in
premailer==3.8.0
    # via spidermon
protego==0.1.16
    # via scrapy
pyasn1==0.4.8
    # via
    #   pyasn1-modules
    #   rsa
    #   service-identity
pyasn1-modules==0.2.8
    # via service-identity
pycparser==2.20
    # via cffi
pydispatcher==2.0.5
    # via scrapy
pyopenssl==20.0.1
    # via scrapy
pyrsistent==0.17.3
    # via jsonschema
python-dateutil==2.8.1
    # via botocore
python-slugify==5.0.0
    # via spidermon
pyyaml==5.4.1
    # via
    #   -r requirements.in
    #   awscli
queuelib==1.6.1
    # via scrapy
requests==2.25.1
    # via
    #   -r requirements.in
    #   monkeylearn
    #   premailer
    #   requests-file
    #   scrapinghub
    #   tldextract
requests-file==1.5.1
    # via tldextract
retrying==1.3.3
    # via scrapinghub
rfc3987==1.3.8
    # via jsonschema
rsa==4.7.2
    # via awscli
s3transfer==0.4.2
    # via
    #   awscli
    #   boto3
schematics==2.1.0
    # via spidermon
scrapinghub==2.3.1
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-pagestorage
scrapinghub-entrypoint-scrapy==0.12.1
    # via
    #   -r requirements.in
    #   scrapy-pagestorage
scrapy==2.6.1
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-crawlera
    #   scrapy-deltafetch
    #   scrapy-dotpersistence
    #   scrapy-magicfields
    #   scrapy-pagestorage
    #   scrapy-querycleaner
    #   scrapy-splitvariants
    #   scrapy-zyte-smartproxy
    #   spidermon
scrapy-crawlera==1.7.2
    # via -r requirements.in
scrapy-deltafetch==1.2.1
    # via -r requirements.in
scrapy-dotpersistence==0.3.0
    # via -r requirements.in
scrapy-magicfields==1.1.0
    # via -r requirements.in
scrapy-pagestorage==0.3.1
    # via -r requirements.in
scrapy-querycleaner==1.0.0
    # via -r requirements.in
scrapy-splash==0.8.0
    # via -r requirements.in
scrapy-splitvariants==1.1.0
    # via -r requirements.in
scrapy-zyte-smartproxy==2.0.0
    # via -r requirements.in
sentry-sdk==1.0.0
    # via spidermon
service-identity==18.1.0
    # via scrapy
six==1.15.0
    # via
    #   automat
    #   jsonschema
    #   monkeylearn
    #   parsel
    #   protego
    #   pyopenssl
    #   python-dateutil
    #   requests-file
    #   retrying
    #   scrapinghub
    #   scrapy-crawlera
    #   scrapy-querycleaner
    #   scrapy-zyte-smartproxy
    #   spidermon
    #   w3lib
slackclient==2.9.3
    # via spidermon
spidermon[monitoring,validation]==1.15.0
    # via -r requirements.in
strict-rfc3339==0.7
    # via jsonschema
text-unidecode==1.3
    # via python-slugify
tldextract==3.2.0
    # via scrapy
twisted==21.2.0
    # via
    #   -r requirements.in
    #   scrapy
typing-extensions==3.10.0.0
    # via aiohttp
urllib3==1.26.4
    # via
    #   -r requirements.in
    #   botocore
    #   requests
    #   sentry-sdk
w3lib==1.22.0
    # via
    #   itemloaders
    #   parsel
    #   scrapy
    #   scrapy-crawlera
    #   scrapy-zyte-smartproxy
webcolors==1.11.1
    # via jsonschema
yarl==1.6.3
    # via aiohttp
zope-interface==5.4.0
    # via
    #   scrapy
    #   twisted

# The following packages are considered to be unsafe in a requirements file:
# setuptools
