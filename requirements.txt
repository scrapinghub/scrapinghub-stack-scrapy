#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile --output-file=requirements.txt requirements.in
#
aiohttp==3.9.4
    # via -r requirements.in
aiosignal==1.3.1
    # via aiohttp
arrow==1.3.0
    # via isoduration
attrs==23.1.0
    # via
    #   aiohttp
    #   automat
    #   jsonschema
    #   referencing
    #   service-identity
    #   twisted
automat==22.10.0
    # via twisted
awscli==1.29.62
    # via
    #   -r requirements.in
    #   scrapy-dotpersistence
boto==2.49.0
    # via
    #   -r requirements.in
    #   spidermon
boto3==1.28.62
    # via
    #   -r requirements.in
    #   spidermon
botocore==1.31.62
    # via
    #   awscli
    #   boto3
    #   s3transfer
cachetools==5.3.1
    # via premailer
certifi==2023.7.22
    # via
    #   requests
    #   sentry-sdk
cffi==1.16.0
    # via cryptography
charset-normalizer==3.3.0
    # via requests
colorama==0.4.4
    # via awscli
constantly==15.1.0
    # via twisted
cryptography==41.0.4
    # via
    #   pyopenssl
    #   scrapy
    #   service-identity
cssselect==1.2.0
    # via
    #   parsel
    #   premailer
    #   scrapy
cssutils==2.7.1
    # via premailer
docutils==0.16
    # via awscli
filelock==3.12.4
    # via tldextract
fqdn==1.5.1
    # via jsonschema
frozenlist==1.4.0
    # via
    #   aiohttp
    #   aiosignal
h2==4.1.0
    # via twisted
hpack==4.0.0
    # via h2
hyperframe==6.0.1
    # via h2
hyperlink==21.0.0
    # via twisted
idna==3.7
    # via
    #   hyperlink
    #   jsonschema
    #   requests
    #   tldextract
    #   yarl
incremental==22.10.0
    # via twisted
isoduration==20.11.0
    # via jsonschema
itemadapter==0.8.0
    # via
    #   itemloaders
    #   scrapy
    #   spidermon
itemloaders==1.1.0
    # via scrapy
jinja2==3.1.3
    # via
    #   -r requirements.in
    #   spidermon
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
    #   itemloaders
    #   parsel
jsonpointer==2.4
    # via jsonschema
jsonschema[format]==4.19.1
    # via spidermon
jsonschema-specifications==2023.7.1
    # via jsonschema
lxml==4.9.3
    # via
    #   -r requirements.in
    #   parsel
    #   premailer
    #   scrapy
markupsafe==2.1.3
    # via jinja2
monkeylearn==3.6.0
    # via -r requirements.in
multidict==6.0.4
    # via
    #   aiohttp
    #   yarl
packaging==23.2
    # via
    #   parsel
    #   scrapy
parsel==1.8.1
    # via
    #   itemloaders
    #   scrapy
pillow==10.3.0
    # via -r requirements.in
premailer==3.10.0
    # via spidermon
priority==1.3.0
    # via twisted
protego==0.3.0
    # via scrapy
pyasn1==0.5.0
    # via
    #   pyasn1-modules
    #   rsa
    #   service-identity
pyasn1-modules==0.3.0
    # via service-identity
pycparser==2.21
    # via cffi
pydispatcher==2.0.7
    # via scrapy
pyopenssl==23.2.0
    # via scrapy
python-dateutil==2.8.2
    # via
    #   arrow
    #   botocore
python-slugify==8.0.1
    # via spidermon
pyyaml==6.0.1
    # via
    #   -r requirements.in
    #   awscli
queuelib==1.6.2
    # via scrapy
referencing==0.30.2
    # via
    #   jsonschema
    #   jsonschema-specifications
requests==2.31.0
    # via
    #   -r requirements.in
    #   monkeylearn
    #   premailer
    #   requests-file
    #   scrapinghub
    #   spidermon
    #   tldextract
requests-file==1.5.1
    # via tldextract
retrying==1.3.4
    # via scrapinghub
rfc3339-validator==0.1.4
    # via jsonschema
rfc3987==1.3.8
    # via jsonschema
rpds-py==0.10.4
    # via
    #   jsonschema
    #   referencing
rsa==4.7.2
    # via awscli
s3transfer==0.7.0
    # via
    #   awscli
    #   boto3
scrapinghub==2.4.0
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-pagestorage
    #   spidermon
scrapinghub-entrypoint-scrapy==0.17.1
    # via
    #   -r requirements.in
    #   scrapy-pagestorage
    #   spidermon
scrapy==2.11.1
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-crawlera
    #   scrapy-deltafetch
    #   scrapy-dotpersistence
    #   scrapy-magicfields
    #   scrapy-pagestorage
    #   scrapy-querycleaner
    #   scrapy-splitvariants
    #   scrapy-zyte-smartproxy
    #   spidermon
scrapy-crawlera==1.7.2
    # via -r requirements.in
scrapy-deltafetch==2.0.1
    # via -r requirements.in
scrapy-dotpersistence==0.3.0
    # via -r requirements.in
scrapy-magicfields==1.1.0
    # via -r requirements.in
scrapy-pagestorage==0.4.0
    # via -r requirements.in
scrapy-querycleaner==1.0.0
    # via -r requirements.in
scrapy-splash==0.9.0
    # via -r requirements.in
scrapy-splitvariants==1.1.0
    # via -r requirements.in
scrapy-zyte-smartproxy==2.2.0
    # via -r requirements.in
sentry-sdk==1.31.0
    # via spidermon
service-identity==23.1.0
    # via scrapy
six==1.16.0
    # via
    #   automat
    #   monkeylearn
    #   python-dateutil
    #   requests-file
    #   retrying
    #   rfc3339-validator
    #   scrapinghub
    #   scrapy-crawlera
    #   scrapy-querycleaner
    #   scrapy-zyte-smartproxy
slack-sdk==3.23.0
    # via spidermon
spidermon[monitoring]==1.20.0
    # via -r requirements.in
text-unidecode==1.3
    # via python-slugify
tldextract==3.6.0
    # via scrapy
twisted[http2]==22.10.0
    # via
    #   -r requirements.in
    #   scrapy
    #   twisted
types-python-dateutil==2.8.19.14
    # via arrow
typing-extensions==4.8.0
    # via twisted
uri-template==1.3.0
    # via jsonschema
urllib3==2.0.7
    # via
    #   -r requirements.in
    #   botocore
    #   requests
    #   sentry-sdk
w3lib==2.1.2
    # via
    #   itemloaders
    #   parsel
    #   scrapy
    #   scrapy-crawlera
    #   scrapy-zyte-smartproxy
webcolors==1.13
    # via jsonschema
yarl==1.9.2
    # via aiohttp
zope-interface==6.1
    # via
    #   scrapy
    #   twisted

# The following packages are considered to be unsafe in a requirements file:
# setuptools
